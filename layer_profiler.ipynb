{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.detection.ofa_mbv3_w12_fasterrcnn import get_ofa_mbv3_w12_fasterrcnn_model, load_pretrained_fasterrcnn, set_training_params\n",
    "# model = get_ofa_mbv3_w12_fcos_model()\n",
    "model = get_ofa_mbv3_w12_fasterrcnn_model()\n",
    "model.eval()\n",
    "# print(model)\n",
    "\n",
    "for name, module in model.named_children():\n",
    "    print(f\"{name}: {type(module).__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "\n",
    "def add_profiling_hooks(model, modules_to_profile={}):\n",
    "    times = {}\n",
    "    handles = []\n",
    "    \n",
    "    def start_hook(name):\n",
    "        def hook(module, input):\n",
    "            torch.cuda.synchronize()\n",
    "            times[name + '_start'] = time.perf_counter()\n",
    "        return hook\n",
    "    \n",
    "    def end_hook(name):\n",
    "        def hook(module, input, output):\n",
    "            torch.cuda.synchronize()\n",
    "            times[name + '_end'] = time.perf_counter()\n",
    "            duration = (times[name + '_end'] - times[name + '_start']) * 1000  # ms\n",
    "            print(f\"Starting {name}\")  # Add start message\n",
    "            duration = (times[name + '_end'] - times[name + '_start']) * 1000  # ms\n",
    "            print(f\"Finishing {name}, took {duration:.2f}ms\")\n",
    "        return hook\n",
    "    \n",
    "    for name, module in modules_to_profile.items():\n",
    "        print(f\"Adding hooks to {name}\")\n",
    "        handles.extend([\n",
    "            module.register_forward_pre_hook(start_hook(name)),\n",
    "            module.register_forward_hook(end_hook(name))\n",
    "        ])\n",
    "    \n",
    "    return handles\n",
    "\n",
    "def run_profiling(model, modules_to_profile, img_size=(1, 3, 800, 800), device='cuda', warmup=10, runs=100):\n",
    "    # Prepare input\n",
    "    dummy_input = torch.randn(img_size).to(device)\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    # Warmup\n",
    "    print(f\"Warming up ({warmup} runs)...\")\n",
    "    with torch.no_grad():\n",
    "        for _ in range(warmup):\n",
    "            model(dummy_input)\n",
    "    \n",
    "    # Profile runs\n",
    "    print(f\"\\nProfiling ({runs} runs)...\")\n",
    "    handles = add_profiling_hooks(model, modules_to_profile)\n",
    "    \n",
    "    try:\n",
    "        with torch.no_grad():\n",
    "            for i in range(runs):\n",
    "                if i % 10 == 0:\n",
    "                    print(f\"Run {i}/{runs}\")\n",
    "                model(dummy_input)\n",
    "    finally:\n",
    "        for handle in handles:\n",
    "            handle.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modules_to_profile = {\n",
    "    'backbone': model.backbone,\n",
    "    'rpn': model.rpn,\n",
    "    'head': model.roi_heads\n",
    "}\n",
    "\n",
    "run_profiling(model, modules_to_profile, img_size=(1, 3, 800, 800), device='cuda', warmup=10, runs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.detection.ofa_mbv3_w12_fcos import get_ofa_mbv3_w12_fcos_model\n",
    "model = get_ofa_mbv3_w12_fcos_model()\n",
    "model.eval()\n",
    "for name, module in model.named_children():\n",
    "    print(f\"{name}: {type(module).__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modules_to_profile = {\n",
    "    'backbone': model.backbone,\n",
    "    'anchor_generator': model.anchor_generator,\n",
    "    'head': model.head\n",
    "}\n",
    "\n",
    "run_profiling(model, modules_to_profile, img_size=(1, 3, 800, 800), device='cuda', warmup=10, runs=50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
